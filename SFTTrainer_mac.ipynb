{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-15T15:03:02.614283Z",
     "start_time": "2024-08-15T15:03:02.610246Z"
    }
   },
   "source": "print(\"SFTTrainer example mac\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFTTrainer example mac\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:44:40.979516Z",
     "start_time": "2024-08-15T15:44:40.976371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imports\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling, HfArgumentParser\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "import wandb"
   ],
   "id": "5044d19b538a9cec",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:15:18.890713Z",
     "start_time": "2024-08-15T15:15:12.639547Z"
    }
   },
   "cell_type": "code",
   "source": "full_dataset = load_dataset(\"lucasmccabe-lmi/openai_humaneval_alpaca_style\", split=\"train\")",
   "id": "7ebf3ac0a97b9a6c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 923/923 [00:00<00:00, 3.57kB/s]\n",
      "Downloading data: 100%|██████████| 57.3k/57.3k [00:01<00:00, 33.9kB/s]\n",
      "Generating train split: 100%|██████████| 164/164 [00:00<00:00, 20693.92 examples/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:23:20.436876Z",
     "start_time": "2024-08-15T15:23:20.430698Z"
    }
   },
   "cell_type": "code",
   "source": "full_dataset[0]",
   "id": "b7918ab0eae4304c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '\\ndef multiply(a, b):\\n    \"\"\"Complete the function that takes two integers and returns \\n    the product of their unit digits.\\n    Assume the input is always valid.\\n    Examples:\\n    multiply(148, 412) should return 16.\\n    multiply(19, 28) should return 72.\\n    multiply(2020, 1851) should return 0.\\n    multiply(14,-15) should return 20.\\n    \"\"\"\\n',\n",
       " 'input': \"The prompt's code is written in Python. Write corresponding response code in Python, as well.\",\n",
       " 'output': '    return abs(a % 10) * abs(b % 10)\\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:23:31.767349Z",
     "start_time": "2024-08-15T15:23:31.764465Z"
    }
   },
   "cell_type": "code",
   "source": "full_dataset",
   "id": "b9fd3bad9b626d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 164\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:24:19.306523Z",
     "start_time": "2024-08-15T15:24:19.296010Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_dict = full_dataset.train_test_split(test_size=0.1)",
   "id": "3aed2cdd4acf5530",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:24:24.280936Z",
     "start_time": "2024-08-15T15:24:24.277568Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_dict",
   "id": "b9e3c85557dfd7de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 147\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 17\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:26:27.255803Z",
     "start_time": "2024-08-15T15:26:27.253458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = dataset_dict[\"train\"]\n",
    "eval_dataset = dataset_dict[\"test\"]"
   ],
   "id": "30fd8d9cb3bd2fba",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:26:43.809960Z",
     "start_time": "2024-08-15T15:26:40.607990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")"
   ],
   "id": "e98df9d3c287bf3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bihan/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:33:05.648622Z",
     "start_time": "2024-08-15T15:33:05.645286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"k_proj\", \"v_proj\"],\n",
    ")"
   ],
   "id": "759dfc26d74fd48b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:33:35.780454Z",
     "start_time": "2024-08-15T15:33:35.777154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        text = f\"### Question: {example['instruction'][i]}\\n ### Answer: {example['output'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ],
   "id": "5ab3de97c56cc961",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:33:38.488554Z",
     "start_time": "2024-08-15T15:33:37.064324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    args=SFTConfig(output_dir=\"/tmp\", max_steps=5, per_device_train_batch_size=1,\n",
    "                   per_device_eval_batch_size=1),\n",
    "    peft_config=peft_config,\n",
    "    formatting_func=formatting_prompts_func,\n",
    ")"
   ],
   "id": "d055bbcec665302",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/147 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 147/147 [00:00<00:00, 6413.84 examples/s]\n",
      "Map: 100%|██████████| 17/17 [00:00<00:00, 3246.81 examples/s]\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:44:52.410479Z",
     "start_time": "2024-08-15T15:44:49.463081Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "4f5a6f13270b3c77",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'wandb' has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:451\u001B[0m, in \u001B[0;36mSFTTrainer.train\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneftune_noise_alpha \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trainer_supports_neftune:\n\u001B[1;32m    449\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trl_activate_neftune(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel)\n\u001B[0;32m--> 451\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001B[39;00m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneftune_noise_alpha \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trainer_supports_neftune:\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/trainer.py:1948\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1946\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1947\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1948\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1949\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1950\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1951\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1952\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1953\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/trainer.py:2436\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2432\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_in_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   2434\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_memory_tracker\u001B[38;5;241m.\u001B[39mstop_and_update_metrics(metrics)\n\u001B[0;32m-> 2436\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2438\u001B[0m run_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_output_dir(trial)\n\u001B[1;32m   2439\u001B[0m checkpoints_sorted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sorted_checkpoints(use_mtime\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, output_dir\u001B[38;5;241m=\u001B[39mrun_dir)\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/trainer.py:3249\u001B[0m, in \u001B[0;36mTrainer.log\u001B[0;34m(self, logs)\u001B[0m\n\u001B[1;32m   3247\u001B[0m output \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mlogs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step}}\n\u001B[1;32m   3248\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mlog_history\u001B[38;5;241m.\u001B[39mappend(output)\n\u001B[0;32m-> 3249\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallback_handler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_log\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontrol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/trainer_callback.py:500\u001B[0m, in \u001B[0;36mCallbackHandler.on_log\u001B[0;34m(self, args, state, control, logs)\u001B[0m\n\u001B[1;32m    498\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_log\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs):\n\u001B[1;32m    499\u001B[0m     control\u001B[38;5;241m.\u001B[39mshould_log \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m--> 500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_event\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mon_log\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontrol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/trainer_callback.py:507\u001B[0m, in \u001B[0;36mCallbackHandler.call_event\u001B[0;34m(self, event, args, state, control, **kwargs)\u001B[0m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_event\u001B[39m(\u001B[38;5;28mself\u001B[39m, event, args, state, control, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    506\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[0;32m--> 507\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m            \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    509\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcontrol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    511\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    513\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    514\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m            \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    519\u001B[0m         \u001B[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001B[39;00m\n\u001B[1;32m    520\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/integrations/integration_utils.py:957\u001B[0m, in \u001B[0;36mWandbCallback.on_log\u001B[0;34m(self, args, state, control, model, logs, **kwargs)\u001B[0m\n\u001B[1;32m    955\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m logs\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    956\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m single_value_scalars:\n\u001B[0;32m--> 957\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wandb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[38;5;241m.\u001B[39msummary[k] \u001B[38;5;241m=\u001B[39m v\n\u001B[1;32m    958\u001B[0m non_scalar_logs \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m logs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m single_value_scalars}\n\u001B[1;32m    959\u001B[0m non_scalar_logs \u001B[38;5;241m=\u001B[39m rewrite_logs(non_scalar_logs)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'wandb' has no attribute 'run'"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:38:59.814626Z",
     "start_time": "2024-08-15T15:38:26.602406Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_imdb = load_dataset(\"imdb\", split=\"train\")",
   "id": "e9bad235ecbd4007",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 7.81k/7.81k [00:00<00:00, 14.7kB/s]\n",
      "Downloading data: 100%|██████████| 21.0M/21.0M [00:05<00:00, 4.19MB/s]\n",
      "Downloading data: 100%|██████████| 20.5M/20.5M [00:04<00:00, 4.11MB/s]\n",
      "Downloading data: 100%|██████████| 42.0M/42.0M [00:07<00:00, 5.64MB/s]\n",
      "Generating train split: 100%|██████████| 25000/25000 [00:00<00:00, 338942.42 examples/s]\n",
      "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 684891.67 examples/s]\n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 820761.37 examples/s]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T15:40:04.975425Z",
     "start_time": "2024-08-15T15:40:04.972344Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_imdb",
   "id": "10a8466847ead743",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T16:00:20.373680Z",
     "start_time": "2024-08-15T16:00:20.365565Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_imdb[0]",
   "id": "cde0011695f72e52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T16:05:12.297551Z",
     "start_time": "2024-08-15T16:05:06.601220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "sft_config = SFTConfig(\n",
    "    dataset_text_field=\"text\",\n",
    "    # max_seq_length=512,\n",
    "    output_dir=\"/tmp\",\n",
    ")\n",
    "trainer = SFTTrainer(\n",
    "    \"facebook/opt-350m\",\n",
    "    train_dataset=dataset_imdb,\n",
    "    args=sft_config,\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "eb87e9a1076bcd68",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 25000/25000 [00:03<00:00, 6789.92 examples/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'wandb' has no attribute 'termwarn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 11\u001B[0m\n\u001B[1;32m      1\u001B[0m sft_config \u001B[38;5;241m=\u001B[39m SFTConfig(\n\u001B[1;32m      2\u001B[0m     dataset_text_field\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m# max_seq_length=512,\u001B[39;00m\n\u001B[1;32m      4\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/tmp\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m )\n\u001B[1;32m      6\u001B[0m trainer \u001B[38;5;241m=\u001B[39m SFTTrainer(\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfacebook/opt-350m\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      8\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mdataset_imdb,\n\u001B[1;32m      9\u001B[0m     args\u001B[38;5;241m=\u001B[39msft_config,\n\u001B[1;32m     10\u001B[0m )\n\u001B[0;32m---> 11\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:451\u001B[0m, in \u001B[0;36mSFTTrainer.train\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneftune_noise_alpha \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trainer_supports_neftune:\n\u001B[1;32m    449\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trl_activate_neftune(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel)\n\u001B[0;32m--> 451\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001B[39;00m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneftune_noise_alpha \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_trainer_supports_neftune:\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/trainer.py:1948\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1946\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1947\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1948\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1949\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1950\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1951\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1952\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1953\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/trainer.py:2212\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2210\u001B[0m model\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m   2211\u001B[0m grad_norm: Optional[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 2212\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallback_handler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_begin\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontrol\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2214\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39meval_on_start:\n\u001B[1;32m   2215\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluate(trial, ignore_keys_for_eval, skip_scheduler\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/trainer_callback.py:460\u001B[0m, in \u001B[0;36mCallbackHandler.on_train_begin\u001B[0;34m(self, args, state, control)\u001B[0m\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_train_begin\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001B[1;32m    459\u001B[0m     control\u001B[38;5;241m.\u001B[39mshould_training_stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_event\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mon_train_begin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontrol\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/trainer_callback.py:507\u001B[0m, in \u001B[0;36mCallbackHandler.call_event\u001B[0;34m(self, event, args, state, control, **kwargs)\u001B[0m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_event\u001B[39m(\u001B[38;5;28mself\u001B[39m, event, args, state, control, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    506\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[0;32m--> 507\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m            \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    509\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcontrol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    511\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    513\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    514\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m            \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    519\u001B[0m         \u001B[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001B[39;00m\n\u001B[1;32m    520\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/integrations/integration_utils.py:900\u001B[0m, in \u001B[0;36mWandbCallback.on_train_begin\u001B[0;34m(self, args, state, control, model, **kwargs)\u001B[0m\n\u001B[1;32m    898\u001B[0m     args\u001B[38;5;241m.\u001B[39mrun_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    899\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialized:\n\u001B[0;32m--> 900\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/machine-learning-book/lib/python3.9/site-packages/transformers/integrations/integration_utils.py:826\u001B[0m, in \u001B[0;36mWandbCallback.setup\u001B[0;34m(self, args, state, model, **kwargs)\u001B[0m\n\u001B[1;32m    824\u001B[0m     init_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m args\u001B[38;5;241m.\u001B[39mrun_name\n\u001B[1;32m    825\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mrun_name \u001B[38;5;241m==\u001B[39m args\u001B[38;5;241m.\u001B[39moutput_dir:\n\u001B[0;32m--> 826\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wandb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtermwarn\u001B[49m(\n\u001B[1;32m    827\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    828\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    829\u001B[0m             repeat\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    830\u001B[0m         )\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wandb\u001B[38;5;241m.\u001B[39mrun \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    833\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wandb\u001B[38;5;241m.\u001B[39minit(\n\u001B[1;32m    834\u001B[0m         project\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWANDB_PROJECT\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuggingface\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    835\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minit_args,\n\u001B[1;32m    836\u001B[0m     )\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'wandb' has no attribute 'termwarn'"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d99d78ae2ead6320"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machine-learning-book)",
   "language": "python",
   "name": "machine-learning-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
